input {
  kafka {
    bootstrap_servers => xxx
    group_id => "test-logstash"
    auto_offset_reset => "earliest"
    consumer_threads => 3
    topics_pattern => "beat-.*"
    codec => json
  }
}

filter {
  if [service] == "target" {
    grok {
      patterns_dir => ["/usr/share/logstash/pipeline"]
      patterns_files_glob => "*.patterns"
      match => {"message" => [
                "%{YEAR:year}/%{MONTHNUM:month}/%{MONTHDAY:day} %{TIME:time}",
                "%{HTTPDATE:logdate}"
                ]
      }
      add_field => {"logtime" => "%{month} %{day} %{year} %{time}"}
    }
    date {
      #match => ['logtime', 'dd/MMM/YYYY:HH:mm:ss Z','YYYY-MM-dd HH:mm:ss.SSS']
      match => ['logtime', 'MM dd yyyy HH:mm:ss.SSS']
    }
  }
  mutate {
    remove_field => ["offset","docker_container","beat"]
  }
}

output {
    file {
        path => "/usr/share/logstash/data/abc.log"
    }
}
